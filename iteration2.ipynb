{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import re\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove non-English reviews\n",
    "def remove_nonenglish_reviews(df):\n",
    "    language_list = list()\n",
    "    for i in range(len(df)):\n",
    "        try: lang = detect(df.text[i])\n",
    "        except: lang = 'none'\n",
    "        language_list.append(lang)\n",
    "    language_list = pd.Series(language_list)\n",
    "    df = df[language_list == 'en']\n",
    "    return df\n",
    "\n",
    "# remove duplicates\n",
    "def remove_duplicates(df):\n",
    "    df = df[df.duplicated(subset = 'text')==False]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenize text\n",
    "def tokenize_text(text):\n",
    "    token_text = re.findall('[A-Za-z]+',text.lower())\n",
    "    clean_text = [WordNetLemmatizer().lemmatize(w) for w in token_text]\n",
    "    final_text = [WordNetLemmatizer().lemmatize(w,pos='v') for w in clean_text]\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorization\n",
    "def build_feature_matrices(X):\n",
    "    vectorizer = CountVectorizer(tokenizer=tokenize_text, max_features=3000)\n",
    "    X_transform = vectorizer.fit_transform(X).toarray()\n",
    "    features_voc = vectorizer.get_feature_names()\n",
    "    return X_transform, features_voc\n",
    "\n",
    "def build_feature_matrices_voc(X):\n",
    "    vectorizer = CountVectorizer(tokenizer=tokenize_text, vocabulary = new_features)\n",
    "    X_transform = vectorizer.fit_transform(X).toarray()\n",
    "    return X_transform\n",
    "\n",
    "def build_feature_matrices_test(X):\n",
    "    # vectorize using loaded features\n",
    "    vectorizer = CountVectorizer(tokenizer=tokenize_text, vocabulary = new_features)\n",
    "    #vectorizer = TfidfVectorizer(tokenizer=tokenize_text, vocabulary = features_voc)\n",
    "    X_transform = vectorizer.fit_transform(X).toarray()\n",
    "    return X_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_features(features_voc):\n",
    "    new_features = list()\n",
    "    for word in features_voc:\n",
    "        if len(list(swn.senti_synsets(word)))==0: continue\n",
    "        if list(swn.senti_synsets(word))[0].obj_score()==1: continue\n",
    "        new_features.append(word)\n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train classifier\n",
    "def build_clf(X, Y):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X, Y)\n",
    "    print(\"Accuracy: \",clf.score(X, Y))\n",
    "    return clf\n",
    "\n",
    "#predictions\n",
    "def predict_clf(X, Y):\n",
    "    predictions = clf.predict(X)\n",
    "    print(\"Accuracy: \",clf.score(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_table('reviews.csv', header=0, error_bad_lines=False, delimiter='|')\n",
    "#clean dataset\n",
    "df = remove_nonenglish_reviews(df)\n",
    "df = remove_duplicates(df)\n",
    "#split dataset\n",
    "train, test = train_test_split(df, test_size = 0.3, random_state = 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vectorize train set, form feature list\n",
    "X_transform_train, features_voc = build_feature_matrices(train['text'])\n",
    "new_features = clean_features(features_voc)\n",
    "X_transform_train = build_feature_matrices_voc(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.909193457417\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "clf = build_clf(X_transform_train, train['label'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vectorize test set\n",
    "X_transform_test = build_feature_matrices_test(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.685203306901\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "predictions = predict_clf(X_transform_test,test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
